\documentclass[size=a4, parskip=half, titlepage=false, toc=flat, toc=bib, 12pt]{scrartcl}

% ---------------------------------------------------------------------------
%  PAQUETES
% ---------------------------------------------------------------------------

% IDIOMA
\usepackage[utf8]{inputenc}

% MATEMÁTICAS
\usepackage{amsmath}    % Paquete básico de matemáticas
%\usepackage{amssymb}	% Fuentes matemáticas
\usepackage{upgreek}
\usepackage{amsthm}     % Teoremas
\usepackage{mathrsfs}   % Fuente para ciertas letras utilizadas en matemáticas
\usepackage{bm}

\usepackage{tgpagella}  % text only
\usepackage{mathpazo}   % math & text


% LISTAS
\usepackage{enumitem}       % Mejores listas
\setlist{leftmargin=.5in}   % Especifica la indentación para las listas.

% Dibujos Tikz
\usepackage{pgf,tikz}
\usepackage{tkz-euclide}
\usetkzobj{all}
\usepackage{mathrsfs}
\usetikzlibrary{arrows, calc,intersections,through,backgrounds}

% Títulos de figuras
\usepackage{capt-of}

% Posición de figuras
\usepackage{float}

% ---------------------------------------------------------------------------
%  RECURSOS
% ---------------------------------------------------------------------------

% Ruta donde buscar gráficos
\graphicspath{{../_assets/}, {_assets/}, {./img/}, {ALGI/img/}, {ALGI/}}

% ---------------------------------------------------------------------------
% ENTORNOS PERSONALIZADOS
% ---------------------------------------------------------------------------

%% DEFINICIONES DE LOS ESTILOS

% Nuevo estilo para definiciones
\newtheoremstyle{definition-style}  % Nombre del estilo
{}                                  % Espacio por encima
{}                                  % Espacio por debajo
{}                                  % Fuente del cuerpo
{}                                  % Identación
{\bfseries\sffamily}                      % Fuente para la cabecera
{.}                                 % Puntuación tras la cabecera
{.5em}                              % Espacio tras la cabecera
{\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}}  % Especificación de la cabecera

% Nuevo estilo para notas
\newtheoremstyle{remark-style}
{10pt}
{10pt}
{}
{}
{\itshape \sffamily}
{.}
{.5em}
{}

% Nuevo estilo para teoremas y proposiciones
\newtheoremstyle{theorem-style}
{}
{}
{}
{}
{\bfseries \sffamily}
{.}
{.5em}
{\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}}

% Nuevo estilo para ejemplos
\newtheoremstyle{example-style}
{10pt}
{10pt}
{}
{}
{\bfseries \sffamily}
{}
{.5em}
{\thmname{#1}\thmnumber{ #2.}\thmnote{ #3.}}

% Nuevo estilo para la demostración

\makeatletter
\renewenvironment{proof}[1][\proofname] {\par\pushQED{\qed}\normalfont\topsep6\p@\@plus6\p@\relax\trivlist\item[\hskip\labelsep\itshape\sffamily#1\@addpunct{.}]\ignorespaces}{\popQED\endtrivlist\@endpefalse}
\makeatother

%% ASIGNACIÓN DE LOS ESTILOS

% Teoremas, proposiciones y corolarios
\theoremstyle{theorem-style}
\newtheorem{nth}{Teorema}[section]
\newtheorem{nprop}{Proposición}[section]
\newtheorem{ncor}{Corolario}[section]
\newtheorem{lema}{Lema}[section]

% Definiciones
\theoremstyle{definition-style}
\newtheorem{ndef}{Definición}[section]

% Notas
\theoremstyle{remark-style}
\newtheorem*{nota}{Nota}

% Ejemplos
\theoremstyle{example-style}
\newtheorem{ejemplo}{Ejemplo}[section]

% Ejercicios y solución
\theoremstyle{definition-style}
\newtheorem{ejer}{Ejercicio}[section]

\theoremstyle{remark-style}
\newtheorem*{sol}{Solución}

% ---------------------------------------------------------------------------
% COMANDOS PERSONALIZADOS
% ---------------------------------------------------------------------------

% Números enteros: \ent
\providecommand{\ent}{\mathbb{Z}}

% Números racionales: \rac
\providecommand{\rac}{\mathbb{Q}}

% Números naturales: \nat
\providecommand{\nat}{\mathbb{N}}


% Valor absoluto: \abs{}
\providecommand{\abs}[1]{\lvert#1\rvert}

% Fracción grande: \ddfrac{}{}
\newcommand\ddfrac[2]{\frac{\displaystyle #1}{\displaystyle #2}}

% Texto en negrita en modo matemática: \bm{}
\newcommand{\bm}[1]{\boldsymbol{#1}}

% Línea horizontal.
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}}

% Restricción de una aplicación.
\newcommand\restr[2]{{% we make the whole thing an ordinary symbol
  \left.\kern-\nulldelimiterspace % automatically resize the bar with \right
  #1 % the function
  \vphantom{\big|} % pretend it's a little taller at normal size
  \right|_{#2} % this is the delimiter
  }}

% Imagen de una aplicación.
\DeclareMathOperator*{\img}{img}

% Divisores de un elemento de un anillo
\DeclareMathOperator*{\rdiv}{div}

% Listas ordenadas con números romanos (i), (ii), etc.
\newenvironment{nlist}
{\begin{enumerate}
    \renewcommand\labelenumi{(\emph{\roman{enumi})}}}
  {\end{enumerate}}

% División por casos con llave a la derecha.
\newenvironment{rcases}
{\left.\begin{aligned}}
    {\end{aligned}\right\rbrace}


% ---------------------------------------------------------------------------
%  COLORES
% ---------------------------------------------------------------------------

\usepackage{xcolor}     % Permite definir y utilizar colores

\definecolor{50}{HTML}{FFEBEE}
\definecolor{300}{HTML}{E57373}
\definecolor{500}{HTML}{F44336}
\definecolor{700}{HTML}{D32F2F}
\definecolor{900}{HTML}{B71C1C}


\setuptoc{toc}{leveldown}

% Ajuste de las líneas y párrafos
\linespread{1.2}
\setlength{\parindent}{0pt}
\setlength{\parskip}{12pt}

% Español
\usepackage[spanish, es-tabla]{babel}

% Matemáticas
\usepackage{amsmath}
\usepackage{amsthm}

% Links
%\usepackage{hyperref}

% Fuentes
%\usepackage{newpxtext,newpxmath}
\usepackage[scale=.9]{FiraMono}
\usepackage{FiraSans}
\usepackage[T1]{fontenc}

\defaultfontfeatures{Ligatures=TeX,Numbers=Lining}
\usepackage[activate={true,nocompatibility},final,tracking=true,factor=1100,stretch=10,shrink=10]{microtype}
\SetTracking{encoding={*}, shape=sc}{0}

\usepackage{graphicx}
\usepackage{float}

% Mejores tablas
\usepackage{booktabs}

\usepackage{adjustbox}

% COLORES

\usepackage{xcolor}

\definecolor{verde}{HTML}{007D51}
\definecolor{esmeralda}{HTML}{045D56}
\definecolor{salmon}{HTML}{FF6859}
\definecolor{amarillo}{HTML}{FFAC12}
\definecolor{morado}{HTML}{A932FF}
\definecolor{azul}{HTML}{0082FB}
\definecolor{error}{HTML}{b00020}

% ENTORNOS
\usepackage[skins, listings, theorems]{tcolorbox}

\newtcolorbox{recuerda}{
  enhanced,
%  sharp corners,
  frame hidden,
  colback=black!10,
	lefttitle=0pt,
  coltitle=black,
  fonttitle=\bfseries\sffamily\scshape,
  titlerule=0.8mm,
  titlerule style=black,
  title=\raisebox{-0.6ex}{\small RECUERDA}
}

\newtcolorbox{nota}{
  enhanced,
%  sharp corners,
  frame hidden,
  colback=black!10,
	lefttitle=0pt,
  coltitle=black,
  fonttitle=\bfseries\sffamily\scshape,
  titlerule=0.8mm,
  titlerule style=black,
  title=\raisebox{-0.6ex}{\small NOTA}
}

\newtcolorbox{error}{
  enhanced,
%  sharp corners,
  frame hidden,
  colback=error!10,
	lefttitle=0pt,
  coltitle=error,
  fonttitle=\bfseries\sffamily\scshape,
  titlerule=0.8mm,
  titlerule style=error,
  title=\raisebox{-0.6ex}{\small ERROR}
}

\newtcblisting{shell}{
  enhanced,
  colback=black!10,
  colupper=black,
  frame hidden,
  opacityback=0,
  coltitle=black,
  fonttitle=\bfseries\sffamily\scshape,
  %titlerule=0.8mm,
  %titlerule style=black,
  %title=Consola,
  listing only,
  listing options={
    style=tcblatex,
    language=sh,
    breaklines=true,
    postbreak=\mbox{\textcolor{black}{$\hookrightarrow$}\space},
    emph={jmml@UbuntuServer, jmml@CentOS},
    emphstyle={\bfseries},
  },
}

\newtcbtheorem[number within=section]{teor}{\small TEOREMA}{
  enhanced,
  sharp corners,
  frame hidden,
  colback=white,
  coltitle=black,
  fonttitle=\bfseries\sffamily,
  %separator sign=\raisebox{-0.65ex}{\Large\MI\symbol{58828}},
  description font=\itshape
}{teor}

\newtcbtheorem[number within=section]{prop}{\small PROPOSICIÓN}{
  enhanced,
  sharp corners,
  frame hidden,
  colback=white,
  coltitle=black,
  fonttitle=\bfseries\sffamily,
  %separator sign=\raisebox{-0.65ex}{\Large\MI\symbol{58828}},
  description font=\itshape
}{prop}

\newtcbtheorem[number within=section]{cor}{\small COROLARIO}{
  enhanced,
  sharp corners,
  frame hidden,
  colback=white,
  coltitle=black,
  fonttitle=\bfseries\sffamily,
  %separator sign=\raisebox{-0.65ex}{\Large\MI\symbol{58828}},
  description font=\itshape
}{cor}

\newtcbtheorem[number within=section]{defi}{\small DEFINICIÓN}{
  enhanced,
  sharp corners,
  frame hidden,
  colback=white,
  coltitle=black,
  fonttitle=\bfseries\sffamily,
  %separator sign=\raisebox{-0.65ex}{\Large\MI\symbol{58828}},
  description font=\itshape
}{defi}

\newtcbtheorem{ejer}{\small EJERCICIO}{
  enhanced,
  sharp corners,
  frame hidden,
  left=0mm,
  right=0mm,
  colback=white,
  coltitle=black,
  fonttitle=\bfseries\sffamily,
  %separator sign=\raisebox{-0.65ex}{\Large\MI\symbol{58828}},
  description font=\itshape,
  nameref/.style={},
}{ejer}

% CÓDIGO
\usepackage{listings}

% CABECERAS
\pagestyle{headings}
\setkomafont{pageheadfoot}{\normalfont\normalcolor\sffamily\small}
\setkomafont{pagenumber}{\normalfont\sffamily}

% ALGORITMOS
\usepackage[vlined,linesnumbered]{algorithm2e}

% Formato de los pies de figura
\setkomafont{captionlabel}{\scshape}
\SetAlCapFnt{\normalfont\scshape}
\SetAlgorithmName{Algoritmo}{Algoritmo}{Lista de algoritmos}

% BIBLIOGRAFÍA
%\usepackage[sorting=none]{biblatex}
%\addbibresource{bibliografia.bib}

\begin{document}

\renewcommand{\proofname}{\normalfont\sffamily\bfseries\small DEMOSTRACIÓN}

\title{Método de ranking en el diseño de un sistema de acceso a la información}
\subject{Trabajo fin de grado}
\author{Johanna Capote Robayna\\
    Doble Grado en Ingeniería Informática y Matemáticas}
\date{}
\publishers{\vspace{2cm}\includegraphics[height=2.5cm]{UGR}\vspace{1cm}}
\maketitle

\newpage

\tableofcontents
\newpage

\section{Introducción}
Fue en la década de los 80, cuando Internet empieza a darse a conocer con unas primeras páginas web de estilo muy básico y sencillo que tardaban mucho en cargarse. Con el transcurso del tiempo la Red fue creciendo a pasos agigantados almacenando un gran volumen de información lo que provocó  un sinfín de procesos y cambios en las formas de gestionarla, y es en ese contexto donde surgen los buscadores para dar respuesta a la necesidad de clasificar y gestionar gran cantidad de información lo más rápido posible.

Un buscador o motor de búsqueda es un sistema de recuperación de información, donde el usuario introduce una serie de términos o palabras clave y el buscador le devuelve una lista de resultados ordenados bajo una serie de criterios. WebCrawler, Lycos, AltaVista o Yahoo entre otros, son los primeros buscadores de la Historia que funcionaban de una forma muy similar, rastreaban la Red y clasificaban las páginas en función de las veces que contenían las palabras clave introducidas. Eran los más utilizados en esa época hasta que en 1998 son desbancados por Google, el mayor motor de búsqueda de todos los tiempos,  que consigue imponerse al resto de buscadores gracias a un nuevo algoritmo de búsqueda (PageRank), capaz de ordenar una gran cantidad de información en poco tiempo.

PageRank, es un algoritmo basado en el Álgebra lineal, Teoría de Grafos y Probabilidad, fue diseñado por Sergey Brin y Lawrence Page, el primero graduado en Matemáticas y el segundo en Informática y ambos estudiantes de doctorado de Informática de la Universidad de Standford. La pregunta que buscaban resolver era clara ``?`en qué orden mostrar los resultados de la búsqueda?''. En 1997 cuando Brin y Page empezaron a trabajar en el diseño del algoritmo se plantearon como objetivo principal que en el gran número de los casos, al menos una de las primeras páginas que se muestran como resultado contenga información útil para el usuario. Hay que tener en cuenta que en esta época Internet no era tan grande como ahora, habían censadas en torno a 100 millones de páginas web y los buscadores más famosos de la época eran capaces de atender 20 millones de consultas al día, mientras que hoy en día Google es capaz de atender a 200 millones de consultas diarias. Pasaremos a explicar como el algoritmo de PageRank es capaz de ordenar estas millones de páginas web en tan poco tiempo.

\section{Introducción al modelo}
Lo primero que hace Google, incluso antes de que el usuario realice la búsqueda es organizar el contenido de Internet ayudándose de un índice. Este índice se va actualizando y va añadiendo páginas nuevas y modificando la información de las páginas ya añadidas en un proceso llamado ``rastreo'', en el cual adquiere información de esas páginas incluyendo los enlaces hacia otra páginas. El índice se ordena con el algoritmo de \textbf{PageRank}, el cual se explicará a continuación, que ordena la lista asignando un PageRank más alto a las páginas que calificará de ``más interesantes'' y un PageRank bajo a las páginas ``menos interesantes''.

Una vez que el usuario introduce su búsqueda esta pasa por varias fases:
\begin{itemize}
\item Análisis de las palabras del usuario. En esta fase se busca entender el significado de la búsqueda, para ello se analiza las palabras usadas y se interpreta lo que el usuario quiere decir con ellas. Este proceso incluye varios pasos como \textbf{interpretar los errores de ortografía} o entender el significado que el usuario le está dando a una palabra con varias acepciones ayudándose de un \textbf{sistema de sinónimos}. Otro aspecto importante de esta fase es el \textbf{algoritmo de novedades}, el cual deduce que en ciertas búsquedas debe mostrar la información más actual, como por ejemplo si el usuario busca ``horóscopo'' o ``resultados del fútbol club Granada'' se está interesando por las últimas publicaciones.
\item Búsqueda de coincidencias. En esta fase se busca entre las páginas del índice aquellas con información coincidente con la búsqueda. Se analiza la frecuencia con la que aparecen las palabras introducidas en las páginas web candidatas y su localización; es decir, si aparecen en el título, encabezamientos o en el cuerpo del texto. Además existen otros algoritmos que analizan si las páginas candidatas pueden resultar interesantes para el usuario, ya que si por ejemplo el usuario busca ``pájaros'' lo más probable es que no quiera encontrar una página con poca información relevante sobre el tema pero en la que se repite muchas veces la palabra ``pájaro''.
\item Mejora del posicionamiento de las páginas útiles. Una vez obtenidas las páginas web con información potencialmente válidas se pasa a clasificar su utilidad con el objetivo de mostrar primero las páginas más útiles para el usuario. En esta fase se analizan varios factores como el número de veces que aparece el término buscado en la página, la fecha de publicación y la calidad de experiencia del usuario en la página. Además se descartan aquellos sitios web con contenido fraudulento o \textit{spam} y se potencia las páginas que en consultas similares hayan sido fiables.
\item Devolver los mejores resultados. En esta parte se busca la diversidad de respuestas. Antes de mostrar el resultado de la búsqueda se analiza el resultado en conjunto, se evalúa si hay muchas páginas centradas en la misma interpretación de la búsqueda o si solo existe un tema en los resultados.
\item Análisis del contexto. Esta fase no se realiza siempre, en ella se busca ``personalizar'' la búsqueda con datos como la ubicación o historial de búsqueda. Con ello se consigue reducir la búsqueda a su entorno, por ejemplo si el usuario es español y busca ``baloncesto'' le saldrá antes información sobre el baloncesto en España que sobre el de otros países o si el usuario busca ``conciertos cerca de mi'' aparecerán los conciertos más cercanos a su residencia. Además mediante el historial de búsqueda personal el buscador consigue mejorar la interpretación de la búsqueda, por ejemplo si el usuario ha buscado anteriormente ``Granada vs Osasuna'' y más adelante busca ``Granada'' puede considerar que el usuario se refiere al equipo de fútbol y no a la ciudad.
\end{itemize}

\newpage

\section{Descripción del problema}
El problema que se va a abordar en este trabajo es conseguir un método de \textit{ranking} para ordenar la información según el interés del usuario. Para ello se investigará las ténicas utilizadas por uno de los mayores motores de búsqueda Google y se aplicarán sobre la base de datos PMSC-UGR. Para abordar el problema nos centramos en la parte preliminar a una búsqueda. Como ya se comentó anteriormente, antes de que el usuario realice una búsqueda en Google las páginas web ya se encuentran previamente ordenadas por el algoritmo PageRank. Este algoritmo  es en el que se centrará este trabajo dividido en dos grandes partes:
\begin{itemize}
\item En la primera parte se realizará un estudio teórico del algoritmo PageRank, en el que se datallará la base matemática de manera formal. En primer lugar se ajustara nuestro problema a un problema de valores y vectores propios y a continuación se desarrollaran varios resultados matemáticos que garantizan la existencia de una solución. (Poner si se llegar a demostrar el teorema ??)
\item En la segunda parte se realizará un estudio práctica sobre el algoritmo PageRank sobre una base de datos y a continuación (... ??)
\end{itemize}

\section{Planificación}

\newpage

\part{Matemáticas}

\section{Modelo matemático}

El algoritmo de PageRank utilizado para ordenar las páginas web tiene una base matemática basado en el álgebra lineal, veamos como se transforma el problema de ordenar las páginas web según su interés en un problema clásico de valores propios y vectores propios.

En primer lugar, vamos a definir el marco donde nos encontramos. Nuestro problema actual es establecer un criterio para ordenar las páginas de la red. Si llamamos $P_1, \dots, P_n$ a cada una de las páginas, siendo $n$ un número natural ($n \in \mathbb{N}$), definimos entonces la importancia $x_i$  de la página $P_i$ como un número real entre $0$ y $1$.

Esta importancia la utilizaremos para elegir que páginas web son las primeras que mostramos en el buscador, ordenándolas de mayor  a menor valor de importancia.
Para calcular este número nos basamos en la información que podemos extraer de la red (sitios, contenido, enlaces de una página web a otra, etc).

En el primer modelo nos quedamos solo con los enlaces entre páginas web. Estos enlaces los podemos representar mediante un grafo dirigido (G), en la cual representamos cada $P_i$ como un nodo del grafo y por cada enlace de una página $P_i$ a $P_j$ añadimos una arista de $P_j$ a $P_i$ indicando el final con una punta de flecha, como se muestra en la imagen.

\includegraphics[width=1.0\textwidth]{./img/grafoini}

Esta información la podemos reflejar en una matriz M de dimensión $nxn$. Tanto en las filas como en las columnas representamos las $n$ páginas y por cada enlace entre una página $j$ a otra página $i$, escribimos un $1$ en la entrada de la
matriz $m_{ij}$ y en el caso de que no haya enlace escribimos un $0$.

\includegraphics[width=1.0\textwidth]{./img/matriz}

Por lo tanto en la columna $j$ estarán los enlaces que salen de la página $P_j$ hacia otras páginas
mientras que en la fila $i$ estarán representados los enlaces a la página $P_i$. De lo que se deduce que esta matriz
no es simétrica ya que una página puede estar citada por otra y ella no citar a ninguna.

En una primera aproximación de querer ordenar las páginas web por ``importancia'' o ``relevancia'' podemos
pensar que la página a la que le lleguen más enlaces (fila con mayor número de $1$) es la que debería
mostrarse primero en el \textit{ranking}. Es decir si $x_j$ es la importancia de $P_j$, esta es proporcional
al número de páginas desde las que hay enlaces a $P_j$.

Sin embargo, la realidad es que el número de enlaces a una cierta página no representa del todo su importancia,
ya que no es lo mismo que esta esté citada por una página cualquiera a que esté citada desde \verb|www.facebook.com| o
\verb|www.apple.com|. Estos dos últimos enlaces deberían ponderar más en importancia que otras citas de
otras páginas web menos relevantes. Por lo que para asignar importancia a una página web, deberemos tener
en cuenta tanto si es una \textbf{página muy citada} como si es una \textbf{página poco citada, pero de sitio ``relevantes''}.

Nos damos cuenta de la que importancia de la página citadora también es importante, por lo que en una segunda aproximación pasamos a decidir que la importancia $x_j$ de una página $P_j$ es proporcional a la suma de las importancias de las páginas que enlazan con $P_j$. El cambio reside en que en la primera aproximación del modelo la importancia de $P_i$ era proporcional al número de páginas que enlazan con $P_i$, mientras que en esta segunda aproximación la importancia de $P_i$ es proporcional a la suma de las importancias de las páginas que enlazan con $P_i$.

Supongamos, por ejemplo, que la página $P_1$ es citada desde las páginas $P_{200}$ y $P_{n}$ ,
 que $P_2$ se cita desde $P_1$ , $P_{50}$ , $P_{200}$ y $P_n$ , mientas que en la última página $P_n$ hay enlaces desde $P_1$ , $P_2$ , $P_{50}$ , $P_{200}$ y $P_{n-1}$. En nuestra asignación anterior, $x_1, \dots , x_n$ deberían
 cumplir entonces que:
 $$ x_1 = K (x_{200} + x_n) $$
 $$ x_2 = K (x_{50} + x_{200} + x_{n-1}) $$
 $$ \vdots $$
 $$x_n = K (x_1 + x_2 + x_{50} + x_{200} + x_{n-1}) $$

donde $K$ es una constante de proporcionalidad. Si nos fijamos, hemos construido un sistema de ecuaciones
donde las soluciones son los posibles valores de $x_1, \dots , x_n$. Este sistema de ecuaciones
lo podemos escribir en términos matriciales:

\includegraphics[width=1.0\textwidth]{./img/matrizejemplo}
%% TODO: cambiar plantilla
Si llamamos $\bm{x}$ al vector de importacias $(x_1 \dots x_n)$, llamamos $\lambda = \frac{1}{K}$ y llamamos
$M$ a la matriz de dimensiones $n x n$ del sistema (matriz asociada al grafo). Nos encontramos
con un problema de valores propios y vectores propios:
$$M \bm{x} = \lambda \bm{x} $$

A este vector $\bm{x}$ le exigimos que sea no negativo, es decir $\bm{x} \leq 0$ ya que representa la importancia
de una página web y también buscamos que sea único ya que como nuestro objetivo final es establecer un
\textit{ranking} de haber más de uno habría que diseñar otro proceso de selección.

\subsection{Las matemáticas entran en juego}

En una primera aproximación, se ha reducido el problema de ordenar las páginas web por importancia a resolver un problema de valores propios y vectores propios.

En primer lugar, vamos a definir el marco donde nos encontramos. Como hemos dicho llamamos $P_1, \dots, P_n$ a cada una de las páginas, siendo $n$ un número natural ($n \in \mathbb{N}$), definimos entonces la importancia $x_i$  de la página $P_i$ como un número real entre $0$ y $1$.

Llamamos $G$ al grafo que representa los enlaces entre páginas web, en el cual representamos cada $P_i$ como un nodo del grafo y por cada enlace de una página $P_i$ a $P_j$ añadimos una arista de $P_j$ a $P_i$. Por último llamamos $M \in  M_n(\mathbb{R})$ a la matriz de adyacencia del grafo, es decir aquella matriz en la que se representan tanto en las filas como en la columnas los nodos y por cada enlace entre $P_i$ y $P_j$ sumamos 1 en la celda m_{ji}$. Por último, llamamos $\boldsymbol{x}$ al vector formado por las importancias de las páginas  $\boldsymbol{x} = (x_1, x_2, \dots , x_n)^T$.

Usaremos la siguiente notación. Dadas $A = (a_{ij}),B = (b_{ij}) \in M_d(\mathbb{C})$ y $x = (x_1, \dots, x_n)\in \mathbb{C}^d$:
\begin{enumerate}
\item $A\geq 0$ si $a_{ij}\geq 0$ , $1 \leq i,j \leq n$. En este caso diremos que la matriz $A$ es no negativa.
\item $A > 0$ si $a_{ij} > 0$ , $1 \leq i, j \leq n$. En este caso diremos que la matriz $A$ es positiva.
\item $A \leq B$ si $a_{ij} \leq b_{ij}$, $1 \leq i,j \leq n$.
\item $x \geq 0$ si $x_i \geq 0$ , $1 \leq i \leq n$. En este caso diremos que el vector $x$ es no negativo.
\item $x > 0$ si $x_i > 0$ , $1 \leq i \leq n$. En esta caso diremos que el vector $x$ es positivo.
\end{enumerate}

No olvidemos que nuestro objetivo es probar que existe un $\lambda$ tal que $M\boldsymbol{x} = \lambda \boldsymbol{x}$, siendo nuestra matriz $M \geq 0$ una matriz no negativa ya que sus entradas son 0 y 1. A continuación trabajaremos con matrices no negativas.
%% TODO Buscar de donde sale esto.
\begin{nprop}
Sean $A \in M_d(\mathbb{C})$ y $x,y \in \mathbb{C}^d$. Si $A > 0$ y $x < y$. Entonces $Ax < Ay$.
\end{nprop}

\begin{ndef}[Matriz irreducible]
Se dice que una matriz $A \in M_d(\mathbb{R})$ no negativa ($A \leq 0$) es irreducible si no existe ninguna permutación (de filas y columnas) que transforma $A$ en una matriz del tipo:
$$\left(
      \begin{array}{{c|c}}
            A_{11}    &    A_{12}  \\\hline
            0         &    A_{22}     \\
      \end{array}   \right)$$
donde $A_{11}$ y $A_{22}$ son matrices cuadradas.
\end{ndef}
\begin{nprop} Sea $A \in M_d(\mathbb{R})$ una matriz no negativa ($A \leq 0$). Son equivalentes:
\begin{enumerate}
\item No existe ninguna permutación (de filas y columnas) que transforma $A$ en una matriz del tipo:
$$\left(
      \begin{array}{{c|c}}
            A_{11}    &    A_{12}  \\\hline
            0         &    A_{22}     \\
      \end{array}   \right)$$
donde $A_{11}$ y $A_{22}$ son matrices cuadradas.
\item La matriz $(I + A)^{n - 1}$, donde $I$ es la identidad $n x n$, tiene todas sus entradas positivas.
\item Si $A$ es la matriz de adyacencia de un grafo, entonces el grafo está fuertemente conectado.
\end{enumerate}
\end{nprop}

Después de esta proposición, si nuestro grafo $(G)$ estuviera fuertemente conectado podríamos decir que su matriz de adyacencia $M$ es irreducible.

\begin{ndef}[Valor propio]
$\lambda$ es valor propio de $A \in M_d(\mathbb{C})$ si y solo si existe un vector no nulo $v \in \mathbb{C}^d$ tal que
$$Av = \lambda v$$
El vector $v$ se llama \textbf{vector propio asociado al valor propio} $\lambda$.
\end{ndef}

\begin{ndef}[Radio espectral]
Sea $A \in M_d(\mathbb{C})$ una matriz y $\sigma (A)$ el conjunto de valores propios de $A$. Definimos el radio espectral de una matriz, denotado por $r(A)$,  como:
$$r(A) = \max \{ | \lambda| : \lambda \in \sigma (A) \} $$
\end{ndef}

\begin{ndef}[Polinomio característico]
Sea $A \in M_d(\mathbb{C})$, definimos el polinomio característico de A, denotado por $p_A(\lambda)$, como:
$$p_A(\lambda) = \det (A - \lambda I) $$
Donde $I$ es la matriz identidad de dimensión $dxd$. Si $\dim(A) = d$, entonces $p(\lambda)$ es de grado $d$.
\end{ndef}
\begin{ndef}[Ecuación característica]
Sea $A \in M_d(\mathbb{C})$, definimos como la ecuación característica a la ecuación $p_A(\lambda) = 0$.
\end{ndef}

\begin{nth}
Sea $A \in M_d(\mathbb{C})$. Entonces, $\lambda \in \mathbb{C}$ es un valor propio de $A$ si y solo si $p_A(\lambda) = 0$. Es decir si $\lambda$ es solución de la ecuación característica.
\end{nth}

\begin{ndef}[Valor propio dominante]
Sea $A \in M_n(\mathbb{C})$S, se dice que tiene valor propio dominante si el espectro
$$\sigma (A) = \{ \lambda_1, \lambda_2 \dots \lambda_n \} \   (r \leq n)$$
cumple:
\begin{itemize}
\item $\lambda_1 > 0$.
\item $\lambda_1$ es una raíz simple del polinomio característico
\item $|\lambda_i| < \lambda_1$ para $i = 2, \dots , r$.
\end{itemize}
A este valor propio dominante lo notaremos como $\lambda_p$.
\end{ndef}

\begin{nth}[Perron, 1907]
Sea $A$ una matriz cuadrada ($A \in M_d(\mathbb{C})$) positiva, $A > 0$. Entonces:
\begin{enumerate}
\item Existe un valor propio dominante $\lambda_p > 0$ tal que $Av = \lambda_p v$ donde el vector propio es $v > 0$.
\item Cualquier otro vector propio positivo de $A$ es un múltiplo de $v$.
\end{enumerate}
\end{nth}

Unos años después Frobenius publica un resultado similar para matrices no negativas e irreducibles.

\begin{nth}[Frobenius, 1908-1912]
Sea $A $ una matriz cuadrada ($A \in M_d(\mathbb{C})$) no negativa ($A \leq 0$). Si $A$ es irreducible, entonces:
\begin{enumerate}
\item Existe un valor propio dominante $\lambda_p > 0$ tal que $A v = \lambda_p v$, donde el vector propio es
$v > 0$.
\item Cualquier vector propio $u \geq 0$ es múltiplo de $v$.
\item Si hay $k$ valores propios de módulo máximo, entonces son las soluciones de $x^k - \lambda^k = 0$.
\end{enumerate}
\end{nth}

Con este último teorema quedaría demostrada la existencia de ese $\lambda$ que cumple $Mx = \lambda x$, suponiendo que nuestra matriz $M$ fuera irreducible. Antes de pasar a demostrar estos teoremas veamos unas propiedades y resultados previos que ayudaran en la demostración de estos.

\section{Resultados previos}

%% TODO preguntar si estoy hay que demostrarlo:
\begin{nprop}
\label{res1}
Sea $A \in M_d(\mathbb{C})$ una matriz cuadrada y $r(A)$ su radio espectral. Entonces:
$$A^n \rightarrow 0 \ ,  n \rightarrow \infty \Leftrightarrow r(A) < 1 $$
\end{nprop}

\begin{ndef}[Multiplicidad algebraica]
Sea $A \in M_d(\mathbb{C})$ una matriz cuadrada y $\lambda_1, \lambda_2, \dots, \lambda_r$ los distintos valores propios de $A$. LLamamos multiplicidad algebraica de $\lambda_i$, a la multiplicidad de $\lambda_i$ como raíz de $p(\lambda)$. A la multiplicidad algebraica de $\lambda_i$ la notamos como $m_i$ y se cumple que $m_1 + m_2 + \dots + m_r = d$.
\end{ndef}

\begin{ndef}[Subespacio propio]
Sea $A \in M_d(\mathbb{C})$ una matriz cuadrada denotamos como $\mathscr{V}_\lambda$ al subespacio vectorial formado por vectores propios asociados al vector propio $\lamdba$. Además se cumple que  $\mathscr{V}_\lambda = Ker(A - \lambda I) = \{ v \in \mathbb{C}^d : Av = \lambda v \}$.
\end{ndef}

\begin{ndef}[Multiplicidad geométrica]
Sea $A \in M_d(\mathbb{C})$ matriz cuadrada y $\lambda_1, \lambda_2, \dots, \lambda_r$ los distintos valores propios de $A$. LLamamos multiplicidad geométrica de $\lambda_i$ a la dimensión del subespacio propio $\mathscr{V}_\lambda_i$. A la multiplicidad geométrica de $\lambda_i$ la denotaremos como $\sigma_i$.
\end{ndef}

\begin{ndef}[Matrices semejantes]
Sean $A, B \in M_d(\mathbb{C})$ dos matrices cuadradas. Se dice que $A$ y $B$ son semejantes si existe una matriz $P \in M_d(\mathbb{C})$ invertible tal que:
$$A = P B P^{-1} $$
\end{ndef}

\begin{nth}[Forma canónica de Jordan]
Toda matriz $A \in M_d(\mathbb{C})$ es semejante a una matriz diagonal por bloques
$$J = \left(
      \begin{array}{{cccc}}
        J_1   &           &         &     \\
              &    J_2    &         &     \\
              &           & \ddots  &     \\
              &           &         & J_r
      \end{array}
\right)$$
donde $1 \leq r \leq d$, y
$$J_i = \left(
      \begin{array}{{ccccc}}
        \lambda_i   &   1       &         &    & \\
              &    \lambda_i    &    1     &    & \\
              &           & \ddots  &     & \\
              &           &         & \lambda_i & 1 \\
              &           &         &           & \lambda_i
      \end{array}
\right), \ \lambda_i \in \sigma(A)$$
La forma canónica de Jordan de una matriz $A$ es única salvo permutaciones de los bloques.
\end{nth}

Para construir esta matriz observamos que cada valor propio aparece en la diagonal de $J$ tantas veces como indique la multiplicidad algebraica. Por ejemplo, si $A$ es una matriz $4x4$ y $p_A(\lambda) = (\lambda - 3)^3 (\lambda - 5)$, las posibles formas de Jordan son:
$$J = \left(
      \begin{array}{{cccc}}
        3   &           &         &     \\
              &    3    &         &     \\
              &         & 3       &     \\
              &        &         & 5
      \end{array}
\right) \ ,  J = \left(
      \begin{array}{{cccc}}
        3   &    1      &         &     \\
            &    3      &         &     \\
            &           & 3       &     \\
            &           &         & 5
      \end{array}
\right)\ , J = \left(
      \begin{array}{{cccc}}
        3     &     1     &         &     \\
              &    3      &   1     &     \\
              &           & 3       &     \\
              &           &         & 5
      \end{array}
\right) $$

\begin{nprop} Sea $A \in M_d(\mathbb{C})$ una matriz con valor propio dominante $\lambda_p$. Entonces la sucesión $\{\frac{1}{ \lambda_p^n } A^n \}_{n\geq 0}$ converge a una matriz $Q \in M_d(\mathbb{C})$ que cumple:
$$ImQ = Ker ( A - \lambda_p I) \ , Q^2 = Q \ , QA = AQ $$
Se dice que $Q$ es una \textbf{proyección espectral de A}.
\end{nprop}

\begin{proof}
Como $\lambda_p$ es simple la matriz de Jordan asociada quedaría $$
  J =
    \left(
      \begin{array}{{c|ccc}}
        \lambda_p     &    0      &   \dots    & 0\\\hline
            0         &           &        &  \\
            \vdots    &           & J^{\star} &  \\
           0          &           &        &
      \end{array}
    \right)
$$ donde $J^{\star}$ contiene los valores propios restantes $\lambda_2, \dots, \lambda_n$.
Como $\lambda_p$ es valor propio dominante tenemos,
$$r(J^{\star}) = \max \{ |\lambda_i| : i = 2, \dots , r \} < \lambda_p $$
Esto equivale a $r(\frac{1}{\lambda_p} J^{\star}) < 1$, si aplicamos el resultado \ref{res1} a la matriz $\frac{1}{\lambda_p} J^{\star}$ obtenemos que $\frac{1}{\lambda_p}^n (J^{\star})^n \rightarrow 0$.

Si vemos $J$ como una matriz diagonal por bloques podemos deducir:
$$J^n =      \left(
      \begin{array}{{c|ccc}}
        \lambda_p^n     &    0      &   \dots    & 0\\\hline
            0         &           &        &  \\
            \vdots    &           & (J^{\star})^n &  \\
           0          &           &        &
      \end{array}
    \right)$$
Utilizando la continuidad del producto tenemos
$$\frac{1}{\lambda_p^n} A^n = P (\frac{1}{\lambda_p^n}  J^n)P^{-1} \rightarrow P \left(
      \begin{array}{{c|ccc}}
            1         &    0      &   \dots    & 0\\\hline
            0         &    0       &    \dots    & 0 \\
            \vdots    &    \vdots  &  \ddots &  \vdots \\
           0          &     0       &    \dots    & 0
      \end{array}   \right) P^{-1}$$
Por lo que queda probada la existencia del límite
$$\lim_{n \to \infty} \frac{1}{\lambda_p^n} A^n  = Q \  \textrm{con} \ Q = P \left(
      \begin{array}{{c|ccc}}
            1         &    0      &   \dots    & 0\\\hline
            0         &    0       &    \dots    & 0 \\
            \vdots    &    \vdots  &  \ddots &  \vdots \\
           0          &     0       &    \dots    & 0
      \end{array}   \right) P^{-1} $$
Comprobamos la propiedades que debe cumplir $Q$.
\begin{itemize}
\item $Im Q = Ker (A - \lambda_p I)$.

Si expresamos la matriz de paso por columnas $P = (p_1 | p_2 | \dots | p_d)$ de la identidad $AP = PJ$ podemos deducir que $Ap_1 = \lambda_p p_1$, ya que:
$$AP = A (p_1 | p_2 | \dots | p_d) = (A p_1 |A p_2 | \dots |A p_d)$$
$$PJ =  (p_1 | p_2 | \dots | p_d) \left(
  \begin{array}{{c|ccc}}
    \lambda_p     &    0      &   \dots    & 0\\\hline
        0         &           &        &  \\
        \vdots    &           & J^{\star} &  \\
       0          &           &        &
  \end{array}
\right)  = ( \lambda_p p_1 | \star | \dots | \star) $$
Y como $\det(P) \neq 0$ el vector $p_1$ no es nulo, de donde deducimos que $ker(A - \lambda_p I)$ tiene dimensión $1$ ya que $ker(A - \lambda_p I) = <p_1>$, a este vector que genera $Q$ se le llama \textbf{vector de Perrón}.

De la definición de $Q$ deducimos
$$QP = P \left(
      \begin{array}{{c|ccc}}
            1         &    0      &   \dots    & 0\\\hline
            0         &    0       &    \dots    & 0 \\
            \vdots    &    \vdots  &  \ddots &  \vdots \\
           0          &     0       &    \dots    & 0
      \end{array}   \right) $$
$$QP = Q (p_1 | p_2 | \dots | p_d) = (Q p_1 |Q p_2 | \dots |Q p_d) $$
$$P \left(
      \begin{array}{{c|ccc}}
            1         &    0      &   \dots    & 0\\\hline
            0         &    0       &    \dots    & 0 \\
            \vdots    &    \vdots  &  \ddots &  \vdots \\
           0          &     0       &    \dots    & 0
      \end{array}   \right) = (p_1 | p_2 | \dots | p_d) \left(
            \begin{array}{{c|ccc}}
                  1         &    0      &   \dots    & 0\\\hline
                  0         &    0       &    \dots    & 0 \\
                  \vdots    &    \vdots  &  \ddots &  \vdots \\
                 0          &     0       &    \dots    & 0
            \end{array}   \right) = (p_1 | 0 | \dots | 0) $$
Por lo que $Qp_1 = p_1$, $Qp_2 = 0$ , $\dots$, $Qp_d = 0$. Y como $p_1, \dots , p_d$ es una base de \mathbb{C}^d$ deducimos que $ImQ = <p_1>$.
\item $Q^2 = Q$.

$$Q^2 = P \left(
      \begin{array}{{c|ccc}}
            1         &    0      &   \dots    & 0\\\hline
            0         &    0       &    \dots    & 0 \\
            \vdots    &    \vdots  &  \ddots &  \vdots \\
           0          &     0       &    \dots    & 0
      \end{array}   \right)^2 P^{-1} = P \left(
            \begin{array}{{c|ccc}}
                  1         &    0      &   \dots    & 0\\\hline
                  0         &    0       &    \dots    & 0 \\
                  \vdots    &    \vdots  &  \ddots &  \vdots \\
                 0          &     0       &    \dots    & 0
            \end{array}   \right) P^{-1} = Q $$
\item $QA = AQ$

Utilizando la continuidad del producto tenemos que
$$QA = (\lim_{n \to \infty} \frac{1}{\lambda_p^n} A^n)A = \lim_{n \to \infty} (\frac{1}{\lambda_p^n} A^n \cdot A) = \lim_{n \to \infty} (A \cdot \frac{1}{\lambda_p^n} A^n) \overset{\textrm{c.p.}} = A ( \lim_{n \to \infty} \frac{1}{\lambda_p^n} A^n) = AQ$$

\end{itemize}
\end{proof}

\newpage

\part{Informática}
\section{Pseudocódigo}

\begin{algorithm}[H]
  \KwData{Matriz de enlaces (m); Número de interaciones (num\_iter); Factor (d)}
  \KwResult{Vector de pesos del PageRank (v)}

  N = M[0].size()\;
  v = random(N, 1)\;
  v = v / max(v)\;
  \For{i $\in$ num\_iter}{
    v = d * m * v + (1 - d)/ N
  }
  \Return v

\end{algorithm}
M_{i,j} =
\begin{bmatrix}
0 & 0 & 0 & 0 & 1 \\
0.5 & 0 & 0 & 0 & 0 \\
0.5 & 0 & 0 & 0 & 0 \\
0 & 1 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 & 0
\end{bmatrix}

donde se representa el enlace de i a j.


\section{Ejemplo}
Para ilustrar mejor el algoritmo, veamos un ejemplo con 5 nodos referenciados de la siguiente forma:

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{./img/grafoejemplo}
\end{figure}
Donde el inicio de la flecha indica el autor que ha sido referenciado y la punta de la flecha indica
que ese autor ha citado el autor del que sale la flecha. Por lo tanto en el algoritmo debería de salir
el autor número $4$ el primero ya que de él salen dos flechas, mientras que de los demás autores salen
como máximo una flecha. Los resultados obtenidos son:

\begin{verbatim}
[[0.2385439 ]
 [0.13138118]
 [0.13138118]
 [0.25334798]
 [0.24534576]]
\end{verbatim}

Donde vemos que el peso mayor se encuentra en el puesto número 4, es decir el cuarto autor sería el
primero en salir en el ranking. Observamos que de los demás nodos siempre sale una sola flecha, sin
embargo el segundo y tercer puesto del ranking es el autor número $5$ y el número $1$. Esto es debido
a que el autor referencia tanto al nodo $2$ como al nodo $3$ por lo que al normalizar estas
referencias el valor de la referencia se divide a la mitad, si le pusiéramos pesos a las flechas,
estas dos flechas que llegan al nodo $1$ valdrían $0.5$. Esto tiene sentido ya que lo que se premia
en este algoritmo es que un articulo este citado por varios autores y no que el mismo autor cite todos
los autores. Por lo tanto si en un artículo se cita solo un autor, el peso de la flecha será uno
mientras que si un autor referencia $N$ autores cada flecha de referencia pesará $\frac{1}{N}$.

\section{Sistema basado en la información}
Un sistema de acceso a la información es un sistema dotado de un conjunto de técnicas para buscar, categorizar, modificar y acceder a la información que se encuentra en un sistema: base de datos, bibliotecas, archivos o internet.

\section{Base de datos}

Para realizar un estudio de \textit{pagerank} se ha utilizado la base de datos \textbf{PMSC-UGR} con
$26759991$ artículos. Esta base de datos basada en articulos científicos de MEDLINE/PubMed  pero
también utilizando SCopus herramienta de Elsevier. En PSMC-UGR se ha hecho el esfuerzo de
quitar las ambigüedades de los nombres de autores, para ello se ha establecido el ORCID, un número
que identifica a cada autor de manera univoca. Cada archivo esta estructurado de la siguiente forma:
\begin{itemize}
\item \textit{PubMedID}. Es un identificador único del articulo proporcionado por PubMed.
\item \textit{Journal}. Es el nombre de la revista donde el artículo ha sido publicado.
\item \textit{ArticleTitle}. Es el título completo del artículo en inglés.
\item \textit{Abstract}. Resumen del artículo.
\item \textit{AuthorList}. Contiene información sobre los autores del artículo. Por cada uno podemos encontrar:
\begin{itemize}
\item \textit{LastName}. Contiene el apellido o el nombre único utilizado.
\item \textit{ForeName}. Contiene el resto del nombre.
\item \textit{Identifier}. Es un identificador único asociado con el nombre (ORCID).
\end{itemize}
\item \textit{MeshHeadingList}. Es un vocabulario controlado por NLM, encabezados de temas médicos (Mesh). Se utiliza para caracterizar el contenido del artículo, utilizando descriptores de ese tesauro.
\item \textit{KeywordList}. Contiene términos controlados en palabras clave que también describen el contenido del artículo.
\end{itemize}

A estos datos se añaden las citas, el $66.78 \%$ de los artículos tienen alguna cita. La media de citas por artículo es de 7 y el total de citas es $3593931$. El numero de citas por articulo sigue una típica distribución \textit{ley de potencia}, donde pocos artículos tienen muchas citas y muchos artículos tienen pocas citas. Por ejemplo, hay $116365$ artículos que tienen solo una cita y hay un artículo que tiene 713 citas.

\textbf{?`?` Esto se refiere a citas y referencias o las referencias van a parte??}
%printbibliography

\end{document}
